{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1MaMPu4TzRS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6930a28-688b-4dca-f528-78ae7a7da0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.115.6 starlette-0.41.3\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.12.2)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn\n",
            "Successfully installed uvicorn-0.32.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi\n",
        "!pip install pyngrok\n",
        "!pip install uvicorn\n",
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uudiEqM02NA5"
      },
      "outputs": [],
      "source": [
        "PROMPT =\"\"\"\n",
        "### Overview\n",
        "You are an AI assistant for a coffee kiosk. Your task is to process customer orders by adding, modifying, or removing drinks, or completing/canceling orders. Respond only in the correct action format without any explanations or additional comments. Interpret customer inputs flexibly and ensure all responses are concise and accurate.\n",
        "---\n",
        "\n",
        "### Menu and Default Options\n",
        "- **Names**:\n",
        "1. **Hot-Only Drinks (핫 Only)**:\n",
        "  - 허브티\n",
        "- **Temperatures**: 핫 (default), only 핫 is available\n",
        "\n",
        "2. **Iced-Only Drinks (아이스 Only)**:\n",
        "  - 토마토주스, 키위주스, 망고스무디, 딸기스무디, 레몬에이드, 복숭아아이스티, 아포카토, 쿠키앤크림\n",
        "  - **Temperatures**: 아이스 (default), only 아이스 is available\n",
        "\n",
        "3. **Hot or Iced Drinks (핫/아이스)**:\n",
        "  - 에스프레소, 카페라떼, 바닐라라떼, 초콜릿라떼, 카푸치노, 아메리카노, 카라멜마끼아또, 카페모카, 말차라떼\n",
        "  - **Temperatures**: 핫 (default)\n",
        "\n",
        "### ALL Items\n",
        "- **Sizes**: 미디움 (default), 라지, 엑스라지\n",
        "- **Add-ons**: Default is \"None\" unless explicitly specified.\n",
        "- Available Add-ons: (샷 추가:[quantity]), (휘핑크림:[quantity]), (바닐라시럽:[quantity]), (카라멜시럽:[quantity])\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The `current_orders` object represents all drinks currently in the customer's order. Each drink is listed with its unique attributes (`name`, `size`, `temperature`, `quantity`, and `add_ons`).\n",
        "\n",
        "- Each unique combination of these attributes is stored as a separate entry.\n",
        "**Structure**:\n",
        "- `\"target_indexes\"`: every index represents 1 cup of drink.\n",
        "- `\"name\"`: The name of the drink.\n",
        "- `\"size\"`: The size of the drink (e.g., `미디움`, `라지`, `엑스라지`).\n",
        "- `\"temperature\"`: The temperature of the drink (`핫` or `아이스`).\n",
        "- `\"quantity\"`: The number of drinks in the group.\n",
        "- `\"add_ons\"`: Add-ons included with the drink (e.g., `(샷 추가: 1)`, `\"None\"`).\n",
        "\n",
        "**Example**:\n",
        "{\n",
        "  \"current_orders\": {\n",
        "    \"drinks\": [\n",
        "    {\"target_indexes\": [\"0-0\", \"0-1\"], \"name\": \"허브티\", \"size\": \"미디움\", \"temperature\": \"핫\", \"quantity\": 2, \"add_ons\": []}\n",
        "    {\"target_indexes\": [\"1-0\"], \"name\": \"딸기스무디\", \"size\": \"미디움\", \"temperature\": \"핫\", \"quantity\": 1, \"add_ons\": []}\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "### Action Types and Expected Formats\n",
        "\n",
        "1. **order_item**: Check the name first if it is available in the menu then Add a drink to the order.\n",
        "  - Validate drink names against the menu.\n",
        "  - Correct minor spacing or typographical errors if the name clearly matches a menu item.\n",
        "  - Use when the customer requests to add a drink.\n",
        "  - **Format**:\n",
        "    \"order_item\", \"name\": \"[name]\", \"size\": \"[size]\", \"temperature\": \"[temperature]\", \"quantity\": [quantity], \"add_ons\": \"[add_ons]\"\n",
        "  - **Default Rules**:\n",
        "    - **Size**: Default to `미디움` if not specified.\n",
        "    - **Temperature**: Default to `핫` unless iced-only.\n",
        "    - **Quantity**: Default to `1` if not specified.\n",
        "    - **Add-ons**: Default to `\"None\"` if not specified.\n",
        "  - **Examples**:\n",
        "    1. Input: \"아이스 아메리카노 두 잔 주세요.\"\n",
        "        Response:\n",
        "        \"order_item\", \"name\": \"아메리카노\", \"size\": \"미디움\", \"temperature\": \"아이스\", \"quantity\": 2, \"add_ons\": \"None\"\n",
        "    2. Input: \"초콜릿라떼 주세요.\"\n",
        "        Response:\n",
        "        \"order_item\", \"name\": \"초콜릿라떼\", \"size\": \"미디움\", \"temperature\": \"핫\", \"quantity\": 1, \"add_ons\": \"None\"\n",
        "\n",
        "\n",
        "1.**Action Type**: `update_item`\n",
        "  - Check if the item exists in the `current_orders`. If not, respond with:\n",
        "    \"invalid_order\", \"reason\": \"Requested item not found in the current order.\"\n",
        "  - Only modify attributes of drinks already present in the current order.\n",
        "  - Ensure that updates (`new_name`, `new_size`, `new_temperature`, `new_add_ons`) have valid values from the menu.\n",
        "  - **Format**:\n",
        "    \"update_item\", \"target_indexes\": [\"[target_indexes]\"], \"updates\": {\"new_name\": \"[new_name]\", \"new_size\": \"[new_size]\", \"new_temperature\": \"[new_temperature]\", \"new_quantity\": [new_quantity], \"new_add_ons\": \"[new_add_ons]\"}\n",
        "  - **Key Rule**:\n",
        "    - Always use the `new_` prefix for attributes in `updates`. For example:\n",
        "      - Updating add-ons: `\"updates\": {\"new_add_ons\": \"(휘핑크림:1)\"}`\n",
        "      - Changing size: `\"updates\": {\"new_size\": \"라지\"}`\n",
        "      - Renaming a drink: `\"updates\": {\"new_name\": \"카페라떼\"}`\n",
        "    - **Rules for Updates**:\n",
        "    - Ensure that `updates` contains only the attributes explicitly mentioned in the input for modification.\n",
        "    - Validate the updated attribute values against the menu and options specified in the prompt.\n",
        "    - If multiple attributes are modified in one input, include all modified attributes in the `updates` object.\n",
        "    - Validate the request:\n",
        "        - Example (invalid item): \"핫 초콜릿을 라지로 바꿔주세요.\" (when the drink is not in the current order)\n",
        "          Response:\n",
        "          \"invalid_order\", \"reason\": \"Drink not found in the current order.\"\n",
        "    - **Examples**:\n",
        "      - Input: \"아메리카노에 휘핑크림 추가해주세요.\"\n",
        "        Example Response(consider when the hot americano has target_indexes as [\"0-0\"]):\n",
        "        \"update_item\", \"target_indexes\": [\"0-0\"], \"updates\": {\"new_add_ons\": \"휘핑크림\"}\n",
        "      - Input: \"핫 아메리카노를 라지로 바꿔주세요.\"\n",
        "        Example Response(consider when the hot americano has target_indexes as [\"0-0\"]):\n",
        "        \"update_item\", \"target_indexes\": [\"0-0\"], \"updates\": {\"new_size\": \"라지\"}\n",
        "      - Input: \"아메리카노 한잔을 라떼로 바꾸어주시고 다른 한잔은 휘핑크림 추가해주세요.\"\n",
        "        Example Response(consider when the hot americano has target_indexes as [\"0-0\",\"0-1\"]):\n",
        "        \"update_item\", \"target_indexes\": [\"0-0\"], \"updates\": {\"new_name\": \"카페라떼\"}\n",
        "        \"update_item\", \"target_indexes\": [\"0-1\"], \"updates\": {\"new_add_ons\": \"휘핑크림\"}\n",
        "\n",
        "3. **delete_item**: Remove specific quantities of a drink from the order.\n",
        "  - **Format**:\n",
        "    \"delete_item\", \"target_indexes\": [\"[target_indexes]\"]\n",
        "  - **Examples**:\n",
        "    - Input: \"핫 초콜릿 한 잔을 삭제해주세요.\"\n",
        "      Response:\n",
        "      \"delete_item\", \"target_indexes\": [\"0-0\"]\n",
        "\n",
        "4. **Invalid Order Function**:\n",
        "  Use the `invalid_order` function to handle requests that:\n",
        "  - Include drink names not in the menu.\n",
        "  - Attempt to modify or delete items not in the current order.\n",
        "  - Contain unrecognized or ambiguous instructions.\n",
        "  - Violate any rules regarding format or attributes.\n",
        "  **Format**:\n",
        "  \"invalid_order\": {\"reason\": \"[reason]\"}\n",
        "  **Examples**:\n",
        "  - Input: \"다리 한잔 주세요.\"\n",
        "    Response:\n",
        "    \"invalid_order\", \"reason\": \"Requested drink is not in the menu.\"\n",
        "  - Input: \"뜨거운 망고스무디 주세요.\"\n",
        "    Response:\n",
        "    \"invalid_order\", \"reason\": \"Requested drink is ice only.\"\n",
        "  - Input: \"핫 초콜릿을 라지로 바꿔주세요.\" (when the drink is not in the current order)\n",
        "    Response:\n",
        "    \"invalid_order\", \"reason\": \"Drink not found in the current order.\"\n",
        "  - Input: \"아아 두 잔 ㅡㅡㅡ.\"\n",
        "    Response:\n",
        "    \"invalid_order\", \"reason\": \"Input is unclear or ambiguous.\"\n",
        "\n",
        "\n",
        "5. **cancel_order**: Cancel the entire order.\n",
        "  - **Format**:\n",
        "    \"cancel_order\"\n",
        "  - **Example**:\n",
        "    - Input: \"주문 취소해주세요.\"\n",
        "      Response:\n",
        "      \"cancel_order\"\n",
        "\n",
        "6. **complete_order**: Complete the order.\n",
        "  - **Format**:\n",
        "    \"complete_order\"\n",
        "  - **Example**:\n",
        "    - Input: \"주문 완료해주세요.\"\n",
        "      Response:\n",
        "      \"complete_order\"\n",
        "\n",
        "7. **invalid_input**: Respond when the input contains an item not in the menu names or an unavailable or unrecognized request.\n",
        "  - **Format**:\n",
        "    \"invalid_input\"\n",
        "  - **Example**:\n",
        "    - Input: \"뜨거운 망고스무디 주세요.\"\n",
        "      Response:\n",
        "      \"invalid_input\"\n",
        "\n",
        "8. **show_menu**: Show Menu.\n",
        "  - **Format**:\n",
        "    \"show_menu\"\n",
        "  - **Example**:\n",
        "    - Input: \"메뉴 보여주세요.\"\n",
        "      Response:\n",
        "      \"show_menu\"\n",
        "\n",
        "---\n",
        "\n",
        "### Key Rules for Responses\n",
        "1. **Multiple Actions**:\n",
        "  - A single input may contain multiple actions. Respond to each action separately.\n",
        "  - **Example**:\n",
        "    Input: \"아이스 아메리카노 두 잔, 카페라떼 라지로 세 잔 주세요.\"\n",
        "    Response:\n",
        "    \"order_item\", \"name\": \"아메리카노\", \"size\": \"미디움\", \"temperature\": \"아이스\", \"quantity\": 2, \"add_ons\": \"None\"\n",
        "    \"order_item\", \"name\": \"카페라떼\", \"size\": \"라지\", \"temperature\": \"핫\", \"quantity\": 3, \"add_ons\": \"None\"\n",
        "\n",
        "2. **Validate Attributes**:\n",
        "  - All attributes for order_item (`name`, `size`, `temperature`, `quantity`, `add_ons`) must match valid menu options. If any attribute is invalid, respond with `\"invalid_input\"`.\n",
        "  - Correct typos and abbreviations if they clearly map to valid options:\n",
        "    - \"아아\" → \"아이스 아메리카노\"\n",
        "    - \"뜨아\" → \"핫 아메리카노\"\n",
        "\n",
        "3. **Default Handling**:\n",
        "  - Use defaults for unspecified attributes:\n",
        "    - **Size**: `미디움`\n",
        "    - **Temperature**: `핫` unless iced-only\n",
        "    - **Quantity**: `1`\n",
        "    - **Add-ons**: `\"None\"`\n",
        "---\n",
        "\n",
        "### Examples of Complex Inputs\n",
        "1. **Multiple Items**:\n",
        "  Input: \"핫 초코 한잔, 아이스 아메리카노 네 잔 주세요.\"\n",
        "  Response:\n",
        "  \"order_item\", \"name\": \"초콜릿라떼\", \"size\": \"미디움\", \"temperature\": \"핫\", \"quantity\": 1, \"add_ons\": \"None\"\n",
        "  \"order_item\", \"name\": \"아메리카노\", \"size\": \"미디움\", \"temperature\": \"아이스\", \"quantity\": 4, \"add_ons\": \"None\"\n",
        "\n",
        "2. **Add and Update**:\n",
        "  Input: \"카라멜마끼아또에 샷 추가해서 한 잔 주세요.\"\n",
        "  Response:\n",
        "  \"order_item\", \"name\": \"카라멜마끼아또\", \"size\": \"미디움\", \"temperature\": \"핫\", \"quantity\": 1, \"add_ons\": \"(샷 추가)\"\n",
        "\n",
        "3. **Invalid Input**:\n",
        "  Input: \"블루베리라떼 주세요.\"\n",
        "  Response:\n",
        "  \"invalid_input\"\n",
        "\"\"\"\n",
        "\n",
        "menu_info = {\n",
        "    # Hot-Only Drinks\n",
        "    \"허브티\": [\"핫\"],\n",
        "    \"에스프레소\": [\"핫\", \"샷 추가\"],\n",
        "\n",
        "    # Iced-Only Drinks\n",
        "    \"토마토주스\": [\"아이스\"],\n",
        "    \"키위주스\": [\"아이스\"],\n",
        "    \"망고스무디\": [\"아이스\"],\n",
        "    \"딸기스무디\": [\"아이스\"],\n",
        "    \"레몬에이드\": [\"아이스\"],\n",
        "    \"복숭아아이스티\": [\"아이스\"],\n",
        "    \"아포카토\": [\"아이스\", \"샷 추가\"],\n",
        "    \"쿠키앤크림\": [\"아이스\", \"휘핑크림\"],\n",
        "\n",
        "    # Hot or Iced Drinks\n",
        "    \"카페라떼\": [\"핫\", \"아이스\", \"샷 추가\"],\n",
        "    \"바닐라라떼\": [\"핫\", \"아이스\", \"샷 추가\", \"바닐라시럽\", \"휘핑크림\"],\n",
        "    \"초콜릿라떼\": [\"핫\", \"아이스\", \"휘핑크림\"],\n",
        "    \"카푸치노\": [\"핫\", \"아이스\", \"샷 추가\", \"휘핑크림\"],\n",
        "    \"아메리카노\": [\"핫\", \"아이스\", \"샷 추가\"],\n",
        "    \"카라멜마끼아또\": [\"핫\", \"아이스\", \"샷 추가\", \"카라멜시럽\", \"휘핑크림\"],\n",
        "    \"카페모카\": [\"핫\", \"아이스\", \"휘핑크림\"],\n",
        "    \"말차라떼\": [\"핫\", \"아이스\", \"휘핑크림\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fcp0QEzO62WP"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "import json\n",
        "import ast\n",
        "\n",
        "class CoffeeKiosk:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"MLP-KTLim/llama-3-Korean-Bllossom-8B\")\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\"MLP-KTLim/llama-3-Korean-Bllossom-8B\", torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",)\n",
        "\n",
        "        self.model.eval()\n",
        "        self.order_items = []  # List to hold each order item as a unique entry\n",
        "        self.previous_inputs = []  # List to hold previous user inputs\n",
        "        self.action_type = \"\"\n",
        "        self.log = \"\"\n",
        "        self.order_log= \"\"\n",
        "        self.wrong = False\n",
        "\n",
        "    def get_console_order_summary(self):\n",
        "        if self.action_type == \"주문 완료\":\n",
        "            return \"주문이 완료되었습니다. 감사합니다.\"\n",
        "        if self.action_type == \"주문 종료\":\n",
        "            return \"주문이 취소되었습니다. 감사합니다.\"\n",
        "        if self.action_type == \"메뉴 제공\":\n",
        "            menu_list = \"\\n\".join(menu_info.keys())\n",
        "            return f\"메뉴는 다음과 같습니다:\\n{menu_list}\"\n",
        "        if not self.order_items:\n",
        "            return \"현재 주문 내역이 없습니다.\"\n",
        "        if self.wrong:\n",
        "            self.wrong = False\n",
        "            return \"\"\n",
        "        summary = \"현재 주문하신 내용은 다음과 같습니다:\\n\"\n",
        "        for item in self.order_items:\n",
        "            details = f\"{item['temperature']} {item['name']} {item['size']} {item['quantity']}잔 \"\n",
        "            if item['add_ons'] != {}:\n",
        "                details += \"추가 옵션은\"\n",
        "                add_ons_details = ', '.join([f\"{k}: {v}번\" for k, v in item['add_ons'].items()])\n",
        "                details += add_ons_details\n",
        "                details += \"입니다.\"\n",
        "            summary += details + \"\\n\"\n",
        "        return summary.strip()\n",
        "\n",
        "    def get_backend_summary(self):\n",
        "        if not self.order_items:\n",
        "            return \"None\"\n",
        "        summary = {\n",
        "                \"drinks\": [\n",
        "                    {\n",
        "                        \"index\": item[\"index\"],\n",
        "                        \"name\": item[\"name\"],\n",
        "                        \"size\": item[\"size\"],\n",
        "                        \"temperature\": item[\"temperature\"],\n",
        "                        \"add_ons\": item[\"add_ons\"],\n",
        "                        \"quantity\": item[\"quantity\"],\n",
        "                        \"quantity_indexes\": item[\"quantity_indexes\"]\n",
        "                    }\n",
        "                    for item in self.order_items\n",
        "                ]\n",
        "            }\n",
        "\n",
        "        return json.dumps(summary, ensure_ascii=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_llama_order_summary(self):\n",
        "        if not self.order_items:\n",
        "            return \"None\"\n",
        "        summary = {\n",
        "                \"drinks\": [\n",
        "                    {\n",
        "                        \"target_indexes\": item[\"quantity_indexes\"],\n",
        "                        \"name\": item[\"name\"],\n",
        "                        \"size\": item[\"size\"],\n",
        "                        \"temperature\": item[\"temperature\"],\n",
        "                        \"quantity\": item[\"quantity\"],\n",
        "                        \"add_ons\": item[\"add_ons\"],\n",
        "\n",
        "                    }\n",
        "                      for item in self.order_items\n",
        "                ]\n",
        "        }\n",
        "\n",
        "        return json.dumps(summary, ensure_ascii=False)\n",
        "\n",
        "    def order_item(self, drink, size, temperature, quantity, add_ons):\n",
        "        # Check if the new item matches any existing items\n",
        "        self.wrong = False\n",
        "        self.order_log = f\"{temperature} {drink} {size} {quantity}잔 주문이 완료되었습니다.\"\n",
        "        for item in self.order_items:\n",
        "            if (item[\"name\"] == drink and\n",
        "                item[\"size\"] == size and\n",
        "                item[\"temperature\"] == temperature and\n",
        "                item[\"add_ons\"] == add_ons):\n",
        "                # Merge into existing item: update quantity and quantity_indexes\n",
        "                current_quantity = item[\"quantity\"]\n",
        "                for i in range(quantity):\n",
        "                    new_index = f\"{item['index']}-{current_quantity + i}\"\n",
        "                    item[\"quantity_indexes\"].append(new_index)\n",
        "                item[\"quantity\"] += quantity\n",
        "                return  # Exit after merging\n",
        "\n",
        "        if drink not in menu_info.keys():\n",
        "          self.wrong = True\n",
        "          self.order_log= f\"{drink}는 메뉴에 없습니다.\"\n",
        "          return \"해당 음료는 메뉴에 없습니다.\"\n",
        "\n",
        "        drink_options = menu_info[drink]\n",
        "        all_in_list = all(x in drink_options for x in [temperature]+list(add_ons.keys()))\n",
        "        if not all_in_list:\n",
        "          self.wrong = True\n",
        "          self.order_log = \"해당 음료는 선택하신 옵션을 제공하지 않습니다.\"\n",
        "          return\n",
        "\n",
        "\n",
        "        # If no matching item, add a new item\n",
        "        new_index = len(self.order_items)  # Assign the next available index\n",
        "        quantity_indexes = [f\"{new_index}-{i}\" for i in range(quantity)]\n",
        "        new_item = {\n",
        "            \"index\": new_index,\n",
        "            \"name\": drink,\n",
        "            \"size\": size,\n",
        "            \"temperature\": temperature,\n",
        "            \"add_ons\": add_ons if add_ons else {},\n",
        "            \"quantity\": quantity,\n",
        "            \"quantity_indexes\": quantity_indexes\n",
        "        }\n",
        "        self.order_items.append(new_item)\n",
        "\n",
        "    def delete_item(self, quantity_indexes):\n",
        "        self.order_log = f\"해당 음료 {len(quantity_indexes)}잔이 삭제되었습니다.\"\n",
        "\n",
        "        item = next((item for item in self.order_items if any(i in quantity_indexes for i in item[\"quantity_indexes\"])), None)\n",
        "        if not item:\n",
        "            self.log = \"해당 음료를 찾을 수 없습니다.\"\n",
        "            return \"해당 음료를 찾을 수 없습니다.\"\n",
        "        # Remove specified quantity indexes\n",
        "        for q_index in quantity_indexes:\n",
        "            if q_index in item[\"quantity_indexes\"]:\n",
        "                item[\"quantity_indexes\"].remove(q_index)\n",
        "        # Update quantity or remove item entirely if all quantities are removed\n",
        "        item[\"quantity\"] = len(item[\"quantity_indexes\"])\n",
        "        if item[\"quantity\"] == 0:\n",
        "            self.order_items = [i for i in self.order_items if i[\"index\"] != item['index']]\n",
        "        self.log = \"선택된 음료가 삭제되었습니다.\"\n",
        "        return \"선택된 음료가 삭제되었습니다.\"\n",
        "\n",
        "\n",
        "    def update_item(self, drink_index, updates):\n",
        "        self.order_log = f\"해당 음료가 업데이트 되었습니다.\"\n",
        "        item = next((item for item in self.order_items if any(i in drink_index for i in item[\"quantity_indexes\"])), None)\n",
        "\n",
        "        if not item:\n",
        "            self.log = \"해당 음료를 찾을 수 없습니다.\"\n",
        "            return \"해당 음료를 찾을 수 없습니다.\"\n",
        "\n",
        "\n",
        "        # 동일한 그룹 내 음료 분리\n",
        "        if len(item[\"quantity_indexes\"]) > 1:\n",
        "            # 기존 항목에서 선택된 index 제거\n",
        "            item[\"quantity_indexes\"].remove(drink_index[0])\n",
        "            item[\"quantity\"] -= 1\n",
        "\n",
        "            # 분리된 항목 추가\n",
        "            new_item = {\n",
        "                \"name\": item[\"name\"],\n",
        "                \"size\": item[\"size\"],\n",
        "                \"temperature\": item[\"temperature\"],\n",
        "                \"quantity\": 1,\n",
        "                \"quantity_indexes\": [drink_index[0]],\n",
        "                \"add_ons\": item[\"add_ons\"],\n",
        "            }\n",
        "            self.order_items.append(new_item)\n",
        "            item = new_item  # 업데이트 대상은 새로 분리된 항목\n",
        "\n",
        "\n",
        "        # Handle updates only for specified quantity indexes\n",
        "        if \"new_name\" in updates:\n",
        "            item[\"name\"] = updates[\"new_name\"]\n",
        "        if \"new_size\" in updates:\n",
        "            item[\"size\"] = updates[\"new_size\"]\n",
        "        if \"new_temperature\" in updates:\n",
        "            item[\"temperature\"] = updates[\"new_temperature\"]\n",
        "        if \"new_quantity\" in updates:\n",
        "            item[\"quantity\"] = updates[\"new_quantity\"]\n",
        "            item[\"quantity_indexes\"] = [f\"{drink_index[0][0]}-{i}\" for i in range(updates[\"new_quantity\"])]\n",
        "        if \"new_add_ons\" in updates:\n",
        "            item[\"add_ons\"] = updates[\"new_add_ons\"]\n",
        "        self.log = \"선택된 음료가 업데이트되었습니다.\"\n",
        "        return \"선택된 음료가 업데이트되었습니다.\"\n",
        "\n",
        "    def cancel_order(self):\n",
        "        self.order_items = []  # Clear the order\n",
        "        self.log = \"주문이 취소되었습니다. 감사합니다!\"\n",
        "        self.order_log = \"\"\n",
        "        return \"주문이 취소되었습니다. 감사합니다!\"\n",
        "\n",
        "    def complete_order(self):\n",
        "        self.__init__()\n",
        "        self.log = \"주문이 완료되었습니다. 감사합니다!\"\n",
        "        self.order_log = \"\"\n",
        "        return \"주문이 완료되었습니다. 감사합니다!\"\n",
        "\n",
        "    def show_menu(self):\n",
        "        self.log = \"메뉴를 보여드리겠습니다.\"\n",
        "        self.order_log = \"\"\n",
        "        return menu_info\n",
        "\n",
        "    def get_log(self):\n",
        "      return self.log\n",
        "\n",
        "    def get_action_type(self):\n",
        "      return self.action_type\n",
        "\n",
        "    def respond_to_input(self, user_input):\n",
        "        \"\"\"\n",
        "        Processes user input, generates a model response, parses the actions, and executes them.\n",
        "        \"\"\"\n",
        "        self.log = \"\"\n",
        "        self.action_type = \"\"\n",
        "        # Store the current user input\n",
        "        self.previous_inputs.append(user_input)\n",
        "\n",
        "        # Construct the prompt for LLaMA\n",
        "        order_summary = self.get_llama_order_summary()\n",
        "        #previous_inputs_summary = \" \".join([f\"Input {i}: {input_}\" for i, input_ in enumerate(self.previous_inputs)])\n",
        "        instruction = (\n",
        "            f\"### INSTRUCTION\"\n",
        "            f\"Respond only in the correct action formats without any explanations or additional comments.when the current order and input below is:\"\n",
        "            f\"Current Order Details:\\n{order_summary}\\n\"\n",
        "            f\"### Input:\\n{user_input}\\n\"\n",
        "            f\"### Response:\"\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
        "        ]\n",
        "\n",
        "        input_ids = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        terminators = [\n",
        "            self.tokenizer.eos_token_id,\n",
        "            self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "        ]\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=2048,\n",
        "            eos_token_id=terminators,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "        print(self.tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True))\n",
        "        response = self.tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "        #response = \"\"\"\n",
        "        # \"order_item\", \"name\": \"아메리카노\", \"size\": \"라지\", \"temperature\": \"아이스\", \"quantity\": \"2\", \"add_ons\": {}\n",
        "        # \"update_item\", \"target_indexes\": [\"0-0\", \"0-1\"], \"updates\": {\"new_name\": \"카페라떼\", \"new_size\": \"스몰\", \"new_temperature\": \"아이스\"}\n",
        "        # \"order_item\", \"name\": \"카페모카\", \"size\": \"미디움\", \"temperature\": \"아이스\", \"quantity\": \"4\", \"add_ons\": {\"휘핑크림\" : \"2\"}\n",
        "\n",
        "        # \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        actions = response.strip().split(\"\\n\")\n",
        "        for action in actions:\n",
        "            self._process_action(action.strip())\n",
        "        print(f'order = { self.order_items}\\n')\n",
        "\n",
        "        # Generate the final response\n",
        "        return {\n",
        "            \"response\": \"명령이 성공적으로 처리되었습니다.\",\n",
        "            \"order_summary\": self.get_console_order_summary()\n",
        "        }\n",
        "\n",
        "    def _process_action(self, action):\n",
        "        \"\"\"\n",
        "        Parses a single action string and executes the corresponding function.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Split the action into command and details\n",
        "            details = {}\n",
        "            if action.strip() == '\"cancel_order\"':\n",
        "                command = \"cancel_order\"\n",
        "            elif action.strip() == '\"complete_order\"':\n",
        "                command = \"complete_order\"\n",
        "            elif action.strip() == '\"show_menu\"':\n",
        "                command = \"show_menu\"\n",
        "            else:\n",
        "                parts = action.split(\",\", 1)\n",
        "                command = parts[0][1:-1]\n",
        "                details = \"{\" + parts[1] + \"}\"\n",
        "                details = ast.literal_eval(details)\n",
        "\n",
        "                if details.get(\"add_ons\") and details.get(\"add_ons\") == \"None\":\n",
        "                    details[\"add_ons\"] = {}\n",
        "\n",
        "            print(f'done = {details}\\ncommand = {command}')\n",
        "\n",
        "            # Execute the corresponding function\n",
        "            if command == \"order_item\":\n",
        "                self.order_item(\n",
        "                    details[\"name\"],\n",
        "                    details[\"size\"],\n",
        "                    details[\"temperature\"],\n",
        "                    int(details[\"quantity\"]),\n",
        "                    details.get(\"add_ons\", {})\n",
        "                )\n",
        "                self.action_type = \"주문 추가\"\n",
        "            elif command == \"delete_item\":\n",
        "                self.delete_item(details[\"target_indexes\"])\n",
        "                self.action_type = \"주문 제거\"\n",
        "            elif command == \"update_item\":\n",
        "                self.update_item(details[\"target_indexes\"], details[\"updates\"])\n",
        "                self.action_type = \"주문 수정\"\n",
        "            elif command == \"cancel_order\":\n",
        "                self.cancel_order()\n",
        "                self.action_type = \"주문 종료\"\n",
        "            elif command == \"complete_order\":\n",
        "                self.complete_order()\n",
        "                self.action_type = \"주문 완료\"\n",
        "            elif command == \"show_menu\":\n",
        "                self.show_menu()\n",
        "                self.action_type = \"메뉴 제공\"\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown action: {command}\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log = \"Response의 포멧이 지원하지 않는 포멧입니다. 다시 실행해주세요\"\n",
        "            raise ValueError(f\"Failed to process action: {action}. Error: {e}\\nResponse의 포멧이 지원하지 않는 포멧입니다. 다시 실행해주세요.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JATuA67AzKqt",
        "outputId": "1c9849f8-8fb0-41f7-eab3-633137ff9176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e8f72c499337>:25: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n"
          ]
        }
      ],
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import logging\n",
        "import uvicorn\n",
        "import socket\n",
        "\n",
        "\n",
        "\n",
        "# FastAPI 앱 생성\n",
        "app = FastAPI()\n",
        "\n",
        "# 로깅 설정\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#kiosk instance\n",
        "kiosk = None\n",
        "\n",
        "\n",
        "# 입력 데이터 모델\n",
        "class InputData(BaseModel):\n",
        "    text: str\n",
        "\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    global kiosk\n",
        "    kiosk = CoffeeKiosk()\n",
        "\n",
        "\n",
        "# 엔드포인트: Llama 모델 호출\n",
        "@app.post(\"/process_text/\")\n",
        "async def process_text(input_data: InputData):\n",
        "    try:\n",
        "        # 입력 텍스트 로깅\n",
        "        logger.info(f\"Received input text: {input_data.text}\")\n",
        "\n",
        "        kiosk.respond_to_input(input_data.text)\n",
        "\n",
        "        response = kiosk.get_console_order_summary()\n",
        "        current_item = kiosk.get_backend_summary()\n",
        "        action_type = kiosk.get_action_type()\n",
        "        log = kiosk.get_log()\n",
        "\n",
        "\n",
        "        # 기본적인 파싱\n",
        "\n",
        "        # 결과 반환\n",
        "        # response : input text에 대한 답변\n",
        "        # current_item : 현재 장바구니 메뉴\n",
        "\n",
        "        # 주문이 완료되었습니다. (실행 함수, ex)업데이트, 변경, 추가, 등 상세내용 출력 요망)\n",
        "        # https://github.com/AI-coffee-Kiosk/Prompting-for-llama/blob/main/prompt_with_2d_array.ipynb\n",
        "\n",
        "        return {\"text\" : f\"{kiosk.order_log}\\n{response}\", \"current_orders\" : current_item, \"action\" : f\"{action_type}\", \"log\" : f\"{log}\"}\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing text: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=\"Error processing the request.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az5ix846Dfbh"
      },
      "outputs": [],
      "source": [
        "!pkill ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9upQZ3LjH0j",
        "outputId": "701ca072-fbc5-4b6f-94f2-ad3df0225fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Device Name: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d71d6a0017ca4844ab710f4ac9c636a9",
            "f6b601ff681b4758b28d6398ac88801d",
            "0d7cedc9d735474a8a010f59519d4e69",
            "0995571a81834eb18fe899b744b78b69",
            "1f917052587a4371b013e75ce9c03a77",
            "c61867f454f34227bf7007c8bed40de7",
            "dc9f28362bd440c0b5973693a2cfc117",
            "d6b2348e504e4b8290e5b7e531db6f24",
            "ff6d327fa5a94f6cbbd3f53ac0770425",
            "4a52b93768b74231812fed95ccec228a",
            "a3474d739b1048f7ba980281e185c91f"
          ]
        },
        "id": "yT2zfPRbzVSW",
        "outputId": "d8a6dd90-a903-4fba-84e2-ee9f129ea87f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://4651-34-75-107-123.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [299]\n",
            "INFO:     Waiting for application startup.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d71d6a0017ca4844ab710f4ac9c636a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.10/dist-packages/uvicorn/server.py:67> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\", line 579, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 65, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 315, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 68, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 332, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"order_item\", \"name\": \"아메리카노\", \"size\": \"미디움\", \"temperature\": \"아이스\", \"quantity\": 2, \"add_ons\": \"None\"\n",
            "done = {'name': '아메리카노', 'size': '미디움', 'temperature': '아이스', 'quantity': 2, 'add_ons': {}}\n",
            "command = order_item\n",
            "order = [{'index': 0, 'name': '아메리카노', 'size': '미디움', 'temperature': '아이스', 'add_ons': {}, 'quantity': 2, 'quantity_indexes': ['0-0', '0-1']}]\n",
            "\n",
            "INFO:     115.88.57.103:0 - \"POST /process_text/ HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "ERROR:__main__:Error processing text: 'index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"update_item\", \"target_indexes\": [\"0-0\"], \"updates\": {\"new_temperature\": \"핫\"}\n",
            "done = {'target_indexes': ['0-0'], 'updates': {'new_temperature': '핫'}}\n",
            "command = update_item\n",
            "order = [{'index': 0, 'name': '아메리카노', 'size': '미디움', 'temperature': '아이스', 'add_ons': {}, 'quantity': 1, 'quantity_indexes': ['0-1']}, {'name': '아메리카노', 'size': '미디움', 'temperature': '핫', 'quantity': 1, 'quantity_indexes': ['0-0'], 'add_ons': {}}]\n",
            "\n",
            "INFO:     115.88.57.103:0 - \"POST /process_text/ HTTP/1.1\" 500 Internal Server Error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-12-09T14:40:12+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-72778b10-808a-4789-ade4-486b96ce6a2d acceptErr=\"failed to accept connection: Listener closed\"\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [299]\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "authtoken = \"2pN9m4ZoaHxU2kdSWXCenyHoOL0_5D6YMAUxH7enHGv7FU1Z4\"\n",
        "password = 0000\n",
        "\n",
        "hf_token = \"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\"\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Hugging Face 토큰 입력\n",
        "login(hf_token)\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(authtoken)\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUux6aJ2XEOQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d71d6a0017ca4844ab710f4ac9c636a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6b601ff681b4758b28d6398ac88801d",
              "IPY_MODEL_0d7cedc9d735474a8a010f59519d4e69",
              "IPY_MODEL_0995571a81834eb18fe899b744b78b69"
            ],
            "layout": "IPY_MODEL_1f917052587a4371b013e75ce9c03a77"
          }
        },
        "f6b601ff681b4758b28d6398ac88801d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c61867f454f34227bf7007c8bed40de7",
            "placeholder": "​",
            "style": "IPY_MODEL_dc9f28362bd440c0b5973693a2cfc117",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0d7cedc9d735474a8a010f59519d4e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b2348e504e4b8290e5b7e531db6f24",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff6d327fa5a94f6cbbd3f53ac0770425",
            "value": 4
          }
        },
        "0995571a81834eb18fe899b744b78b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a52b93768b74231812fed95ccec228a",
            "placeholder": "​",
            "style": "IPY_MODEL_a3474d739b1048f7ba980281e185c91f",
            "value": " 4/4 [00:06&lt;00:00,  1.50s/it]"
          }
        },
        "1f917052587a4371b013e75ce9c03a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c61867f454f34227bf7007c8bed40de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc9f28362bd440c0b5973693a2cfc117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6b2348e504e4b8290e5b7e531db6f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6d327fa5a94f6cbbd3f53ac0770425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a52b93768b74231812fed95ccec228a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3474d739b1048f7ba980281e185c91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}